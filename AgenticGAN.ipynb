{
  "cells": [
    {
      "cell_type": "markdown",
<<<<<<< HEAD
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oyyPoodles/AgenticGAN---Tester-/blob/main/AgenticGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
=======
      "id": "ee8a7285",
      "metadata": {
        "id": "ee8a7285"
      },
      "source": [
        "AgenticGAN Tecter: Realistic Failure Case Generation to Improve Model Robustness\n",
        "\n",
        "ðŸ“Œ Project Overview\n",
        "AgenticGAN-Tester is a novel AI framework that autonomously discovers and generates realistic failure cases for deep learning models using an agent-driven GAN approach. Unlike traditional adversarial attacks (which produce pixel-level noise) or simple data augmentation, this system generates highly realistic, diverse, and semantically meaningful images that actually cause the model to fail.\n",
        "\n",
        "These failure samples are then curated, analyzed, and used for retraining, closing the loop between failure discovery and model improvement â€” making AI systems more robust to real-world edge cases and out-of-distribution (OOD) inputs."
>>>>>>> 301c94f (updated codes)
      ]
    },
    {
      "cell_type": "markdown",
<<<<<<< HEAD
      "id": "ee8a7285",
      "metadata": {
        "id": "ee8a7285"
      },
      "source": [
        "AgenticGAN Tecter: Realistic Failure Case Generation to Improve Model Robustness\n",
        "\n",
        "ðŸ“Œ Project Overview\n",
        "AgenticGAN-Tester is a novel AI framework that autonomously discovers and generates realistic failure cases for deep learning models using an agent-driven GAN approach. Unlike traditional adversarial attacks (which produce pixel-level noise) or simple data augmentation, this system generates highly realistic, diverse, and semantically meaningful images that actually cause the model to fail.\n",
        "\n",
        "These failure samples are then curated, analyzed, and used for retraining, closing the loop between failure discovery and model improvement â€” making AI systems more robust to real-world edge cases and out-of-distribution (OOD) inputs."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a206883",
      "metadata": {
        "id": "2a206883"
      },
      "source": [
        "Phase I: Train Base Classifier (CNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5347eb01",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5347eb01",
        "outputId": "9cf10c97-22bc-4ec6-fddd-d52d965af69b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 170M/170M [00:03<00:00, 47.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10] | Loss: 992.0804\n",
            "Epoch [2/10] | Loss: 657.9469\n",
            "Epoch [3/10] | Loss: 558.4597\n",
            "Epoch [4/10] | Loss: 490.8395\n",
            "Epoch [5/10] | Loss: 438.9479\n",
            "Epoch [6/10] | Loss: 398.8691\n",
            "Epoch [7/10] | Loss: 360.5920\n",
            "Epoch [8/10] | Loss: 327.6600\n",
            "Epoch [9/10] | Loss: 298.3398\n",
            "Epoch [10/10] | Loss: 271.5688\n",
            "âœ… Base Classifier Trained & Saved at: models/classifier.pth\n"
          ]
        }
      ],
      "source": [
        "# âœ… Import Libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Reproducibility (IMPORTANT for GAN testing)\n",
        "# ------------------------\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Paths\n",
        "# ------------------------\n",
        "os.makedirs(\"models\", exist_ok=True)\n",
        "os.makedirs(\"generated_images\", exist_ok=True)\n",
        "os.makedirs(\"failure_cases\", exist_ok=True)\n",
        "os.makedirs(\"retrained_model\", exist_ok=True)\n",
        "os.makedirs(\"results/gradcam_outputs\", exist_ok=True)\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Device\n",
        "# ------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ CIFAR-10 Dataset\n",
        "# ------------------------\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5),\n",
        "                         (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "train_data = datasets.CIFAR10(\n",
        "    root=\"./data\", train=True, download=True, transform=transform\n",
        ")\n",
        "test_data = datasets.CIFAR10(\n",
        "    root=\"./data\", train=False, download=True, transform=transform\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True, num_workers=2)\n",
        "test_loader  = DataLoader(test_data, batch_size=64, shuffle=False, num_workers=2)\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Robust Classifier\n",
        "# ------------------------\n",
        "class RobustCNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(64, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(64, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(128, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(8 * 8 * 128, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.classifier(x)\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Initialize Model\n",
        "# ------------------------\n",
        "model = RobustCNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Train Loop\n",
        "# ------------------------\n",
        "def train_classifier(epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}] | Loss: {running_loss:.4f}\")\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Train & Save\n",
        "# ------------------------\n",
        "train_classifier(epochs=10)\n",
        "\n",
        "save_path = \"models/classifier.pth\"\n",
        "torch.save(model.state_dict(), save_path)\n",
        "print(f\"âœ… Base Classifier Trained & Saved at: {save_path}\")\n"
=======
      "id": "2a206883",
      "metadata": {
        "id": "2a206883"
      },
      "source": [
        "Phase I: Train Base Classifier (CNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5347eb01",
      "metadata": {
        "id": "5347eb01",
        "outputId": "70c994a3-a927-4738-b6f5-885cc21ba204"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "Epoch [1/10], Loss: 1062.2195\n",
            "Epoch [2/10], Loss: 692.4332\n",
            "Epoch [3/10], Loss: 578.9396\n",
            "Epoch [4/10], Loss: 513.1268\n",
            "Epoch [5/10], Loss: 461.3128\n",
            "Epoch [6/10], Loss: 420.2112\n",
            "Epoch [7/10], Loss: 382.6153\n",
            "Epoch [8/10], Loss: 349.7227\n",
            "Epoch [9/10], Loss: 318.9631\n",
            "Epoch [10/10], Loss: 291.5230\n",
            "âœ… Base Classifier Trained & Saved at: models/classifier.pth\n"
          ]
        }
      ],
      "source": [
        "# âœ… Import Libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Reproducibility (IMPORTANT for GAN testing)\n",
        "# ------------------------\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Paths\n",
        "# ------------------------\n",
        "os.makedirs(\"models\", exist_ok=True)\n",
        "os.makedirs(\"generated_images\", exist_ok=True)\n",
        "os.makedirs(\"failure_cases\", exist_ok=True)\n",
        "os.makedirs(\"retrained_model\", exist_ok=True)\n",
        "os.makedirs(\"results/gradcam_outputs\", exist_ok=True)\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Device\n",
        "# ------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ CIFAR-10 Dataset\n",
        "# ------------------------\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5),\n",
        "                         (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "train_data = datasets.CIFAR10(\n",
        "    root=\"./data\", train=True, download=True, transform=transform\n",
        ")\n",
        "test_data = datasets.CIFAR10(\n",
        "    root=\"./data\", train=False, download=True, transform=transform\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True, num_workers=2)\n",
        "test_loader  = DataLoader(test_data, batch_size=64, shuffle=False, num_workers=2)\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Robust Classifier\n",
        "# ------------------------\n",
        "class RobustCNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(64, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(64, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(128, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(8 * 8 * 128, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.classifier(x)\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Initialize Model\n",
        "# ------------------------\n",
        "model = RobustCNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Train Loop\n",
        "# ------------------------\n",
        "def train_classifier(epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}] | Loss: {running_loss:.4f}\")\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Train & Save\n",
        "# ------------------------\n",
        "train_classifier(epochs=10)\n",
        "\n",
        "save_path = \"models/classifier.pth\"\n",
        "torch.save(model.state_dict(), save_path)\n",
        "print(f\"âœ… Base Classifier Trained & Saved at: {save_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db18b887",
      "metadata": {
        "id": "db18b887"
      },
      "source": [
        "Phase II: Build and Train GAN from Scratch Model\n",
        "a) GAN Import and Setup"
>>>>>>> 301c94f (updated codes)
      ]
    },
    {
      "cell_type": "markdown",
<<<<<<< HEAD
      "id": "db18b887",
      "metadata": {
        "id": "db18b887"
      },
      "source": [
        "Phase II: Build and Train GAN from Scratch Model\n",
        "a) GAN Import and Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "806ad8a0",
      "metadata": {
        "id": "806ad8a0"
      },
      "source": [
        "a) Imports and Setup for GAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "fc6513be",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc6513be",
        "outputId": "1cc71f6a-4558-414f-caaf-132709e66cbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# ------------------------\n",
        "# ðŸ”¹ GAN Imports & Setup\n",
        "# ------------------------\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.utils import save_image, make_grid\n",
        "import torch.nn.utils.spectral_norm as spectral_norm\n",
        "import os\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Device (KEEP CONSISTENT)\n",
        "# ------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Base Project Path\n",
        "# ------------------------\n",
        "base_path = \"./\"\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Folder Paths\n",
        "# ------------------------\n",
        "gen_img_path = os.path.join(base_path, \"generated_images\")\n",
        "model_path = os.path.join(base_path, \"models\")\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Create Folders\n",
        "# ------------------------\n",
        "os.makedirs(gen_img_path, exist_ok=True)\n",
        "os.makedirs(model_path, exist_ok=True)\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ GAN Hyperparameters\n",
        "# ------------------------\n",
        "latent_dim = 128          # â†‘ increased for richer latent space\n",
        "img_size = 32\n",
        "batch_size = 128\n",
        "epochs = 50\n",
        "\n",
        "# Learning rates will be set in optimizer cell (do NOT set betas here)\n",
        "lr = 2e-4\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6c0fc90",
      "metadata": {
        "id": "a6c0fc90"
      },
      "source": [
        "b) Loading CIFAR-10 Dataset for GAN Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "06b0633e",
      "metadata": {
        "id": "06b0633e"
      },
      "outputs": [],
      "source": [
        "# ------------------------\n",
        "# ðŸ”¹ CIFAR-10 Dataset for GAN\n",
        "# ------------------------\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(img_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5),\n",
        "                         (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "gan_dataset = datasets.CIFAR10(\n",
        "    root=\"./data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "gan_loader = DataLoader(\n",
        "    gan_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30208b22",
      "metadata": {
        "id": "30208b22"
      },
      "source": [
        "c) Building GAN - Generator and Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "760efa1b",
      "metadata": {
        "id": "760efa1b"
      },
      "outputs": [],
      "source": [
        "# ------------------------\n",
        "# ðŸ”¹ GAN Architecture (Generator + Discriminator)\n",
        "# ------------------------\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.utils.spectral_norm as spectral_norm\n",
        "import os\n",
        "\n",
        "# âš ï¸ Device already defined earlier â€” do NOT redefine here\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Generator\n",
        "# ------------------------\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim=128, num_classes=10, img_size=32):\n",
        "        super().__init__()\n",
        "        self.label_emb = nn.Embedding(num_classes, num_classes)\n",
        "        self.init_size = img_size // 4\n",
        "\n",
        "        self.fc = nn.Linear(latent_dim + num_classes,\n",
        "                            256 * self.init_size * self.init_size)\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.BatchNorm2d(256),\n",
        "\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(256, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(64, 3, 3, padding=1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z, labels):\n",
        "        label_embed = self.label_emb(labels)\n",
        "        x = torch.cat((z, label_embed), dim=1)\n",
        "        x = self.fc(x)\n",
        "        x = x.view(x.size(0), 256, self.init_size, self.init_size)\n",
        "        return self.net(x)\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Discriminator (PatchGAN + Spectral Norm)\n",
        "# ------------------------\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        def block(in_c, out_c, normalize=True):\n",
        "            layers = [spectral_norm(nn.Conv2d(in_c, out_c, 4, 2, 1))]\n",
        "            if normalize:\n",
        "                layers.append(nn.BatchNorm2d(out_c))\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "            return layers\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *block(3, 64, normalize=False),\n",
        "            *block(64, 128),\n",
        "            *block(128, 256),\n",
        "            spectral_norm(nn.Conv2d(256, 1, 4, 1, 0))\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        return self.model(img)\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Initialize Models\n",
        "# ------------------------\n",
        "generator = Generator().to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Hinge Loss\n",
        "# ------------------------\n",
        "def d_loss(real_logits, fake_logits):\n",
        "    return torch.mean(F.relu(1.0 - real_logits)) + \\\n",
        "           torch.mean(F.relu(1.0 + fake_logits))\n",
        "\n",
        "def g_loss(fake_logits):\n",
        "    return -torch.mean(fake_logits)\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Optimizers\n",
        "# ------------------------\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=2e-4, betas=(0.0, 0.9))\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=2e-4, betas=(0.0, 0.9))\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Save Paths\n",
        "# ------------------------\n",
        "os.makedirs(\"models\", exist_ok=True)\n",
        "generator_save_path = \"models/gan_generator.pth\"\n",
        "discriminator_save_path = \"models/gan_discriminator.pth\"\n"
      ]
    },
    {
=======
      "id": "806ad8a0",
      "metadata": {
        "id": "806ad8a0"
      },
      "source": [
        "a) Imports and Setup for GAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc6513be",
      "metadata": {
        "id": "fc6513be",
        "outputId": "8fcf9663-7574-4916-d735-3b2c35a8ce1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "# ------------------------\n",
        "# ðŸ”¹ GAN Imports & Setup\n",
        "# ------------------------\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.utils import save_image, make_grid\n",
        "import torch.nn.utils.spectral_norm as spectral_norm\n",
        "import os\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Device (KEEP CONSISTENT)\n",
        "# ------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Base Project Path\n",
        "# ------------------------\n",
        "base_path = \"./\"\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Folder Paths\n",
        "# ------------------------\n",
        "gen_img_path = os.path.join(base_path, \"generated_images\")\n",
        "model_path = os.path.join(base_path, \"models\")\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Create Folders\n",
        "# ------------------------\n",
        "os.makedirs(gen_img_path, exist_ok=True)\n",
        "os.makedirs(model_path, exist_ok=True)\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ GAN Hyperparameters\n",
        "# ------------------------\n",
        "latent_dim = 128          # â†‘ increased for richer latent space\n",
        "img_size = 32\n",
        "batch_size = 128\n",
        "epochs = 50\n",
        "\n",
        "# Learning rates will be set in optimizer cell (do NOT set betas here)\n",
        "lr = 2e-4\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6c0fc90",
      "metadata": {
        "id": "a6c0fc90"
      },
      "source": [
        "b) Loading CIFAR-10 Dataset for GAN Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06b0633e",
      "metadata": {
        "id": "06b0633e"
      },
      "outputs": [],
      "source": [
        "# ------------------------\n",
        "# ðŸ”¹ CIFAR-10 Dataset for GAN\n",
        "# ------------------------\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(img_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5),\n",
        "                         (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "gan_dataset = datasets.CIFAR10(\n",
        "    root=\"./data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "gan_loader = DataLoader(\n",
        "    gan_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30208b22",
      "metadata": {
        "id": "30208b22"
      },
      "source": [
        "c) Building GAN - Generator and Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "760efa1b",
      "metadata": {
        "id": "760efa1b"
      },
      "outputs": [],
      "source": [
        "# ------------------------\n",
        "# ðŸ”¹ GAN Architecture (Generator + Discriminator)\n",
        "# ------------------------\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.utils.spectral_norm as spectral_norm\n",
        "import os\n",
        "\n",
        "# âš ï¸ Device already defined earlier â€” do NOT redefine here\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Generator\n",
        "# ------------------------\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim=128, num_classes=10, img_size=32):\n",
        "        super().__init__()\n",
        "        self.label_emb = nn.Embedding(num_classes, num_classes)\n",
        "        self.init_size = img_size // 4\n",
        "\n",
        "        self.fc = nn.Linear(latent_dim + num_classes,\n",
        "                            256 * self.init_size * self.init_size)\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.BatchNorm2d(256),\n",
        "\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(256, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(64, 3, 3, padding=1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z, labels):\n",
        "        label_embed = self.label_emb(labels)\n",
        "        x = torch.cat((z, label_embed), dim=1)\n",
        "        x = self.fc(x)\n",
        "        x = x.view(x.size(0), 256, self.init_size, self.init_size)\n",
        "        return self.net(x)\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Discriminator (PatchGAN + Spectral Norm)\n",
        "# ------------------------\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        def block(in_c, out_c, normalize=True):\n",
        "            layers = [spectral_norm(nn.Conv2d(in_c, out_c, 4, 2, 1))]\n",
        "            if normalize:\n",
        "                layers.append(nn.BatchNorm2d(out_c))\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "            return layers\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *block(3, 64, normalize=False),\n",
        "            *block(64, 128),\n",
        "            *block(128, 256),\n",
        "            spectral_norm(nn.Conv2d(256, 1, 4, 1, 0))\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        return self.model(img)\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Initialize Models\n",
        "# ------------------------\n",
        "generator = Generator().to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Hinge Loss\n",
        "# ------------------------\n",
        "def d_loss(real_logits, fake_logits):\n",
        "    return torch.mean(F.relu(1.0 - real_logits)) + \\\n",
        "           torch.mean(F.relu(1.0 + fake_logits))\n",
        "\n",
        "def g_loss(fake_logits):\n",
        "    return -torch.mean(fake_logits)\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Optimizers\n",
        "# ------------------------\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=2e-4, betas=(0.0, 0.9))\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=2e-4, betas=(0.0, 0.9))\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Save Paths\n",
        "# ------------------------\n",
        "os.makedirs(\"models\", exist_ok=True)\n",
        "generator_save_path = \"models/gan_generator.pth\"\n",
        "discriminator_save_path = \"models/gan_discriminator.pth\"\n"
      ]
    },
    {
>>>>>>> 301c94f (updated codes)
      "cell_type": "markdown",
      "id": "e226deff",
      "metadata": {
        "id": "e226deff"
      },
      "source": [
        "d) Train the GAN"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 5,
      "id": "060faca2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "060faca2",
        "outputId": "d1911647-ae81-4d49-e68e-ec4bdec1f661"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:24<00:00, 16.15it/s, D_loss=1.6790, G_loss=-0.0480]\n",
            "Epoch 2/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:23<00:00, 16.48it/s, D_loss=1.6594, G_loss=0.7203]\n",
            "Epoch 3/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:23<00:00, 16.60it/s, D_loss=1.4744, G_loss=-0.5169]\n",
            "Epoch 4/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:23<00:00, 16.52it/s, D_loss=1.3552, G_loss=1.0007]\n",
            "Epoch 5/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:23<00:00, 16.46it/s, D_loss=1.4626, G_loss=0.7392]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ–¼ï¸ Saved generated samples: ./generated_images/epoch_5.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:23<00:00, 16.46it/s, D_loss=1.6733, G_loss=0.8466]\n",
            "Epoch 7/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:23<00:00, 16.49it/s, D_loss=1.4998, G_loss=0.4251]\n",
            "Epoch 8/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:23<00:00, 16.46it/s, D_loss=1.4438, G_loss=0.4746]\n",
            "Epoch 9/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:23<00:00, 16.65it/s, D_loss=1.2934, G_loss=-0.1944]\n",
            "Epoch 10/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:23<00:00, 16.54it/s, D_loss=1.4254, G_loss=0.2537]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ–¼ï¸ Saved generated samples: ./generated_images/epoch_10.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 11/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:23<00:00, 16.48it/s, D_loss=1.3265, G_loss=0.8410]\n",
            "Epoch 12/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:23<00:00, 16.58it/s, D_loss=1.4383, G_loss=0.4660]\n",
            "Epoch 13/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:23<00:00, 16.37it/s, D_loss=1.8109, G_loss=0.0074]\n",
            "Epoch 14/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:23<00:00, 16.48it/s, D_loss=1.8057, G_loss=-0.3482]\n",
            "Epoch 15/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:23<00:00, 16.52it/s, D_loss=1.3966, G_loss=0.2712]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ–¼ï¸ Saved generated samples: ./generated_images/epoch_15.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 16/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:23<00:00, 16.47it/s, D_loss=1.4733, G_loss=-0.0278]\n",
            "Epoch 17/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:23<00:00, 16.35it/s, D_loss=1.3684, G_loss=0.6917]\n",
            "Epoch 18/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:23<00:00, 16.34it/s, D_loss=1.3672, G_loss=1.4914]\n",
            "Epoch 19/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:24<00:00, 16.18it/s, D_loss=1.6669, G_loss=1.0595]\n",
            "Epoch 20/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:24<00:00, 16.20it/s, D_loss=0.9205, G_loss=0.0652]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ–¼ï¸ Saved generated samples: ./generated_images/epoch_20.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 21/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:24<00:00, 16.27it/s, D_loss=0.9720, G_loss=1.1081]\n",
            "Epoch 22/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:24<00:00, 16.28it/s, D_loss=1.0406, G_loss=0.1973]\n",
            "Epoch 23/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:24<00:00, 16.26it/s, D_loss=0.9589, G_loss=0.0059]\n",
            "Epoch 24/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:23<00:00, 16.47it/s, D_loss=0.9798, G_loss=-0.0693]\n",
            "Epoch 25/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:23<00:00, 16.51it/s, D_loss=0.8271, G_loss=0.5226]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ–¼ï¸ Saved generated samples: ./generated_images/epoch_25.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 26/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:23<00:00, 16.30it/s, D_loss=0.9648, G_loss=0.1943]\n",
            "Epoch 27/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:24<00:00, 16.28it/s, D_loss=1.1910, G_loss=-0.0945]\n",
            "Epoch 28/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:24<00:00, 16.29it/s, D_loss=1.1753, G_loss=0.7106]\n",
            "Epoch 29/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:24<00:00, 16.29it/s, D_loss=1.3027, G_loss=-0.2476]\n",
            "Epoch 30/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:23<00:00, 16.34it/s, D_loss=1.1921, G_loss=0.5107]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ–¼ï¸ Saved generated samples: ./generated_images/epoch_30.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 31/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:23<00:00, 16.49it/s, D_loss=1.0300, G_loss=1.0091]\n",
            "Epoch 32/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:23<00:00, 16.61it/s, D_loss=1.3434, G_loss=0.0988]\n",
            "Epoch 33/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:23<00:00, 16.37it/s, D_loss=1.3299, G_loss=-0.0767]\n",
            "Epoch 34/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:23<00:00, 16.44it/s, D_loss=1.3070, G_loss=1.4422]\n",
            "Epoch 35/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:23<00:00, 16.42it/s, D_loss=1.1309, G_loss=0.0395]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ–¼ï¸ Saved generated samples: ./generated_images/epoch_35.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 36/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:23<00:00, 16.42it/s, D_loss=1.0858, G_loss=0.4635]\n",
            "Epoch 37/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:23<00:00, 16.51it/s, D_loss=0.9736, G_loss=0.9562]\n",
            "Epoch 38/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:23<00:00, 16.40it/s, D_loss=1.2725, G_loss=-0.2588]\n",
            "Epoch 39/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:23<00:00, 16.60it/s, D_loss=0.8250, G_loss=0.7076]\n",
            "Epoch 40/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:23<00:00, 16.65it/s, D_loss=1.0932, G_loss=0.0408]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ–¼ï¸ Saved generated samples: ./generated_images/epoch_40.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 41/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:23<00:00, 16.54it/s, D_loss=1.4313, G_loss=-0.3723]\n",
            "Epoch 42/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:23<00:00, 16.56it/s, D_loss=1.2039, G_loss=0.8698]\n",
            "Epoch 43/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:23<00:00, 16.53it/s, D_loss=0.6482, G_loss=-0.0819]\n",
            "Epoch 44/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:23<00:00, 16.52it/s, D_loss=1.1980, G_loss=1.3661]\n",
            "Epoch 45/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:23<00:00, 16.57it/s, D_loss=0.8776, G_loss=1.2080]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ–¼ï¸ Saved generated samples: ./generated_images/epoch_45.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 46/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:23<00:00, 16.72it/s, D_loss=0.7020, G_loss=0.7861]\n",
            "Epoch 47/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:23<00:00, 16.64it/s, D_loss=0.7048, G_loss=0.4037]\n",
            "Epoch 48/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:23<00:00, 16.43it/s, D_loss=0.8717, G_loss=0.0904]\n",
            "Epoch 49/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:23<00:00, 16.48it/s, D_loss=1.5328, G_loss=0.2279]\n",
            "Epoch 50/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:24<00:00, 16.29it/s, D_loss=0.8265, G_loss=-0.1304]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ–¼ï¸ Saved generated samples: ./generated_images/epoch_50.png\n",
            "âœ… GAN Training Complete & Models Saved\n"
=======
      "execution_count": null,
      "id": "060faca2",
      "metadata": {
        "id": "060faca2",
        "outputId": "27b5a8bf-6a68-4a4d-acef-c0c85c016881"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [09:02<00:00,  1.39s/it, D_loss=0.6931, G_loss=0.7209]\n",
            "Epoch 2/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [09:27<00:00,  1.45s/it, D_loss=0.6885, G_loss=0.7591]\n",
            "Epoch 3/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [09:20<00:00,  1.43s/it, D_loss=0.6880, G_loss=0.7848]\n",
            "Epoch 4/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [12:12<00:00,  1.87s/it, D_loss=0.6861, G_loss=0.7872]\n",
            "Epoch 5/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [13:18<00:00,  2.04s/it, D_loss=0.6876, G_loss=0.7766]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ–¼ï¸ Saved generated samples: ./generated_images\\epoch_5.png\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [13:10<00:00,  2.02s/it, D_loss=0.6876, G_loss=0.7833]\n",
            "Epoch 7/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [13:08<00:00,  2.02s/it, D_loss=0.6893, G_loss=0.7786]\n",
            "Epoch 8/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [13:09<00:00,  2.02s/it, D_loss=0.6890, G_loss=0.7793]\n",
            "Epoch 9/50:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 361/391 [08:03<00:40,  1.34s/it, D_loss=0.6829, G_loss=0.7924]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 55\u001b[39m\n\u001b[32m     52\u001b[39m     fm_loss = torch.mean(torch.abs(real_feats.mean(\u001b[32m0\u001b[39m) - fake_feats.mean(\u001b[32m0\u001b[39m)))\n\u001b[32m     53\u001b[39m     g_loss = g_loss_basic + \u001b[32m0.05\u001b[39m * fm_loss\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m     \u001b[43mg_loss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m     optimizer_G.step()\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# Train Discriminator\u001b[39;00m\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\autograd\\__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\autograd\\graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
>>>>>>> 301c94f (updated codes)
          ]
        }
      ],
      "source": [
        "# ------------------------\n",
        "# ðŸ”¹ GAN Training Loop (Hinge Loss + PatchGAN)\n",
        "# ------------------------\n",
        "from torchvision.utils import save_image\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "gen_img_path = os.path.join(base_path, \"generated_images\")\n",
        "os.makedirs(gen_img_path, exist_ok=True)\n",
        "\n",
        "epochs = 50\n",
        "g_steps = 1   # Hinge GAN does NOT need multi-step G\n",
        "\n",
        "generator.train()\n",
        "discriminator.train()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    loop = tqdm(\n",
        "        enumerate(gan_loader),\n",
        "        total=len(gan_loader),\n",
        "        desc=f\"Epoch {epoch+1}/{epochs}\"\n",
        "    )\n",
        "\n",
        "    for _, (real_imgs, labels) in loop:\n",
        "        real_imgs = real_imgs.to(device)\n",
        "        batch_size = real_imgs.size(0)\n",
        "\n",
        "        # -------------------------\n",
        "        # ðŸ”¹ Train Discriminator\n",
        "        # -------------------------\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        z = torch.randn(batch_size, latent_dim, device=device)\n",
        "        fake_imgs = generator(z, labels.to(device)).detach()\n",
        "\n",
        "        real_logits = discriminator(real_imgs)\n",
        "        fake_logits = discriminator(fake_imgs)\n",
        "\n",
        "        loss_D = d_loss(real_logits, fake_logits)\n",
        "        loss_D.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # -------------------------\n",
        "        # ðŸ”¹ Train Generator\n",
        "        # -------------------------\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        z = torch.randn(batch_size, latent_dim, device=device)\n",
        "        fake_imgs = generator(z, labels.to(device))\n",
        "\n",
        "        fake_logits = discriminator(fake_imgs)\n",
        "        loss_G = g_loss(fake_logits)\n",
        "\n",
        "        loss_G.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        loop.set_postfix(\n",
        "            D_loss=f\"{loss_D.item():.4f}\",\n",
        "            G_loss=f\"{loss_G.item():.4f}\"\n",
        "        )\n",
        "\n",
        "    # -------------------------\n",
        "    # ðŸ”¹ Save Samples\n",
        "    # -------------------------\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        z = torch.randn(25, latent_dim, device=device)\n",
        "        sample_labels = torch.randint(0, 10, (25,), device=device)\n",
        "        samples = generator(z, sample_labels)\n",
        "\n",
        "        save_path = os.path.join(gen_img_path, f\"epoch_{epoch+1}.png\")\n",
        "        save_image(samples, save_path, nrow=5, normalize=True)\n",
        "        print(f\"ðŸ–¼ï¸ Saved generated samples: {save_path}\")\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Save Final Models\n",
        "# ------------------------\n",
        "torch.save(generator.state_dict(), generator_save_path)\n",
        "torch.save(discriminator.state_dict(), discriminator_save_path)\n",
        "print(\"âœ… GAN Training Complete & Models Saved\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35925676",
      "metadata": {
        "id": "35925676"
      },
      "source": [
        "Phase III: Agent to find Failure Images (Misclassified GAN Output)"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 6,
      "id": "82346c4e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82346c4e",
        "outputId": "0d15cd7b-b35b-4068-f1a9-c1bf6b7b9515"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Failure Mining Complete â€” 1435 failure cases saved.\n"
=======
      "execution_count": null,
      "id": "82346c4e",
      "metadata": {
        "id": "82346c4e",
        "outputId": "d207c8d7-8736-44b7-c242-d2473662ffd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Failure Image Collection Completed â€” 2000 failure cases saved!\n"
>>>>>>> 301c94f (updated codes)
          ]
        }
      ],
      "source": [
        "# ------------------------\n",
        "# ðŸ”¹ Phase III: Agentic Failure Case Mining\n",
        "# ------------------------\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.utils import save_image\n",
        "import os\n",
        "\n",
        "# âš ï¸ device already defined earlier â€” reuse it\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Paths\n",
        "# ------------------------\n",
        "base_path = \"./\"\n",
        "failure_path = os.path.join(base_path, \"failure_cases\")\n",
        "model_path = os.path.join(base_path, \"models\")\n",
        "os.makedirs(failure_path, exist_ok=True)\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Load Trained Classifier (SAME AS PHASE I)\n",
        "# ------------------------\n",
        "classifier = RobustCNN().to(device)\n",
        "classifier.load_state_dict(\n",
        "    torch.load(os.path.join(model_path, \"classifier.pth\"), map_location=device)\n",
        ")\n",
        "classifier.eval()\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Load Trained GAN Generator (SAME AS PHASE II)\n",
        "# ------------------------\n",
        "generator = Generator().to(device)\n",
        "generator.load_state_dict(\n",
        "    torch.load(os.path.join(model_path, \"gan_generator.pth\"), map_location=device)\n",
        ")\n",
        "generator.eval()\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Agentic Failure Mining\n",
        "# ------------------------\n",
        "num_samples = 2000\n",
        "failure_count = 0\n",
        "confidence_threshold = 0.90   # classifier confidence\n",
        "\n",
        "for i in range(num_samples):\n",
        "    z = torch.randn(1, latent_dim, device=device)\n",
        "    label = torch.randint(0, 10, (1,), device=device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        fake_img = generator(z, label)\n",
        "        logits = classifier(fake_img)\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "\n",
        "        max_confidence, pred_class = probs.max(dim=1)\n",
        "\n",
        "    # ------------------------\n",
        "    # ðŸ”¹ Failure Condition\n",
        "    # ------------------------\n",
        "    if max_confidence < confidence_threshold:\n",
        "        failure_count += 1\n",
        "        save_image(\n",
        "            fake_img,\n",
        "            os.path.join(failure_path, f\"failure_{failure_count}.png\"),\n",
        "            normalize=True\n",
        "        )\n",
        "\n",
        "print(f\"âœ… Failure Mining Complete â€” {failure_count} failure cases saved.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5dfd883b",
      "metadata": {
        "id": "5dfd883b"
      },
      "source": [
        "Phase IV: Retrain Classifier with Failure GAN Images (Hardening Step\n",
        "ðŸŽ¯ Goal of this Phase:\n",
        "\n",
        "âœ… Load the original classifier\n",
        "âœ… Create a new training dataset = Real CIFAR-10 Images + GAN Failure Images\n",
        "âœ… Assign labels to GAN failure images using classifier prediction (pseudo-labeling)\n",
        "âœ… Retrain (fine-tune) the classifier so it becomes more robust and smarter\n",
        "âœ… Save improved model in /retrained_model/)\n",
        "\n",
        "a) Prepare Mixed Dataset (Real + Failure Images)"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 7,
      "id": "71c47a73",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71c47a73",
        "outputId": "729b3e8d-5185-4b41-fb7e-e2a9bd7071ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Mixed Dataset Prepared\n",
            "ðŸ“ Real images: ./retrained_data/real\n",
            "ðŸ“ Failure images (pseudo-labeled): ./retrained_data/failure\n"
=======
      "execution_count": null,
      "id": "71c47a73",
      "metadata": {
        "id": "71c47a73",
        "outputId": "8151b769-b7a9-46a6-f832-317bf6dc2320"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Real + Failure Images Saved for Retraining\n",
            "ðŸ“ Path: f:\\Projects !!\\AgenticGAN_Project\\retrained_data\n"
>>>>>>> 301c94f (updated codes)
          ]
        }
      ],
      "source": [
        "# ------------------------\n",
        "# ðŸ”¹ Phase IV-A: Prepare Mixed Dataset (Real + GAN Failure Images)\n",
        "# ------------------------\n",
        "import os\n",
        "import shutil\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image\n",
        "from PIL import Image\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Paths\n",
        "# ------------------------\n",
        "base_path = \".\"\n",
        "\n",
        "data_path = os.path.join(base_path, \"data\")\n",
        "failure_path = os.path.join(base_path, \"failure_cases\")\n",
        "retrain_data_path = os.path.join(base_path, \"retrained_data\")\n",
        "\n",
        "real_path = os.path.join(retrain_data_path, \"real\")\n",
        "failure_path_labeled = os.path.join(retrain_data_path, \"failure\")\n",
        "\n",
        "os.makedirs(real_path, exist_ok=True)\n",
        "os.makedirs(failure_path_labeled, exist_ok=True)\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Transform (same normalization as classifier)\n",
        "# ------------------------\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(32),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5),\n",
        "                         (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Load CIFAR-10 (Real Images)\n",
        "# ------------------------\n",
        "cifar_train = datasets.CIFAR10(\n",
        "    root=data_path,\n",
        "    train=True,\n",
        "    download=False,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Save Real Images (Subset)\n",
        "# ------------------------\n",
        "num_real = 5000\n",
        "\n",
        "for idx in range(num_real):\n",
        "    img, label = cifar_train[idx]\n",
        "    save_image(\n",
        "        img,\n",
        "        os.path.join(real_path, f\"real_{idx}_label_{label}.png\"),\n",
        "        normalize=True\n",
        "    )\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Load Trained Classifier (for pseudo-labeling)\n",
        "# ------------------------\n",
        "classifier = RobustCNN().to(device)\n",
        "classifier.load_state_dict(\n",
        "    torch.load(os.path.join(base_path, \"models\", \"classifier.pth\"),\n",
        "               map_location=device)\n",
        ")\n",
        "classifier.eval()\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Pseudo-label GAN Failure Images\n",
        "# ------------------------\n",
        "failure_files = os.listdir(failure_path)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for idx, file in enumerate(failure_files):\n",
        "        img = Image.open(os.path.join(failure_path, file)).convert(\"RGB\")\n",
        "        img_tensor = transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "        logits = classifier(img_tensor)\n",
        "        pseudo_label = logits.argmax(dim=1).item()\n",
        "\n",
        "        save_image(\n",
        "            img_tensor.squeeze(0),\n",
        "            os.path.join(failure_path_labeled,\n",
        "                         f\"failure_{idx}_label_{pseudo_label}.png\"),\n",
        "            normalize=True\n",
        "        )\n",
        "\n",
        "print(\"âœ… Mixed Dataset Prepared\")\n",
        "print(f\"ðŸ“ Real images: {real_path}\")\n",
        "print(f\"ðŸ“ Failure images (pseudo-labeled): {failure_path_labeled}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d49535b8",
      "metadata": {
        "id": "d49535b8"
      },
      "source": [
        "b) Creating Custom Dataset Loader with Pseudo-labels"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 9,
      "id": "08c2b75f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08c2b75f",
        "outputId": "77ae338a-e0a1-45cf-df05-3e8e747bc5f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Mixed Dataset Loaded\n",
            "ðŸ“Œ Total Samples: 6435\n",
            "ðŸ“ Real Images: /content/retrained_data/real\n",
            "ðŸ“ Failure Images: /content/retrained_data/failure\n"
=======
      "execution_count": null,
      "id": "08c2b75f",
      "metadata": {
        "id": "08c2b75f",
        "outputId": "d7daec23-c169-45ab-860b-a058883f254a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Mixed Dataset Loaded!\n",
            "ðŸ“Œ Total Samples: 7000\n",
            "ðŸ“ Real Images From: f:\\Projects !!\\AgenticGAN_Project\\retrained_data\\real\n",
            "ðŸ“ Failure Images From: f:\\Projects !!\\AgenticGAN_Project\\retrained_data\\failure\n"
>>>>>>> 301c94f (updated codes)
          ]
        }
      ],
      "source": [
        "# ------------------------\n",
        "# ðŸ”¹ Phase IV-B: Mixed Dataset Loader (Correct)\n",
        "# ------------------------\n",
        "import os\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "# âš ï¸ device, classifier already defined earlier\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Paths\n",
        "# ------------------------\n",
        "base_path = \".\"\n",
        "retrain_data_path = os.path.join(base_path, \"retrained_data\")\n",
        "real_path = os.path.join(retrain_data_path, \"real\")\n",
        "failure_path = os.path.join(retrain_data_path, \"failure\")\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Image Transform (Same as Classifier)\n",
        "# ------------------------\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5),\n",
        "                         (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Mixed Dataset (Labels pre-encoded in filenames)\n",
        "# ------------------------\n",
        "class MixedDataset(Dataset):\n",
        "    def __init__(self, real_dir, fail_dir, transform=None):\n",
        "        self.samples = []\n",
        "        self.transform = transform\n",
        "\n",
        "        # Real images\n",
        "        for fname in os.listdir(real_dir):\n",
        "            label = int(fname.split(\"label_\")[1].split(\".\")[0])\n",
        "            self.samples.append(\n",
        "                (os.path.join(real_dir, fname), label)\n",
        "            )\n",
        "\n",
        "        # Failure images (pseudo-labeled already)\n",
        "        for fname in os.listdir(fail_dir):\n",
        "            label = int(fname.split(\"label_\")[1].split(\".\")[0])\n",
        "            self.samples.append(\n",
        "                (os.path.join(fail_dir, fname), label)\n",
        "            )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.samples[idx]\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ DataLoader\n",
        "# ------------------------\n",
        "mixed_dataset = MixedDataset(real_path, failure_path, transform)\n",
        "mixed_loader = DataLoader(\n",
        "    mixed_dataset,\n",
        "    batch_size=64,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "print(\"âœ… Mixed Dataset Loaded\")\n",
        "print(\"ðŸ“Œ Total Samples:\", len(mixed_dataset))\n",
        "print(\"ðŸ“ Real Images:\", os.path.abspath(real_path))\n",
        "print(\"ðŸ“ Failure Images:\", os.path.abspath(failure_path))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc4cd29e",
      "metadata": {
        "id": "dc4cd29e"
      },
      "source": [
        "c) Re-training the Classifier (Fine - Tune)"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 10,
      "id": "68a300f3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68a300f3",
        "outputId": "44861035-1841-4929-f30b-ef382bce6748"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5] | Loss: 43.7675 | Accuracy: 84.01%\n",
            "Epoch [2/5] | Loss: 39.5246 | Accuracy: 85.77%\n",
            "Epoch [3/5] | Loss: 37.3832 | Accuracy: 86.48%\n",
            "Epoch [4/5] | Loss: 36.3480 | Accuracy: 86.56%\n",
            "Epoch [5/5] | Loss: 34.2418 | Accuracy: 87.74%\n",
            "âœ… Classifier Hardened & Saved at: /content/retrained_model/classifier_hardened.pth\n"
=======
      "execution_count": null,
      "id": "68a300f3",
      "metadata": {
        "id": "68a300f3",
        "outputId": "69f73473-1dc4-48b3-d568-9c63350bb5a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch [1/5] â€” Loss: 11.0685\n",
            "âœ… Epoch [2/5] â€” Loss: 3.8666\n",
            "âœ… Epoch [3/5] â€” Loss: 2.1502\n",
            "âœ… Epoch [4/5] â€” Loss: 1.2730\n",
            "âœ… Epoch [5/5] â€” Loss: 0.7850\n",
            "âœ… Classifier Retrained & Saved at: f:\\Projects !!\\AgenticGAN_Project\\retrained_model\n"
>>>>>>> 301c94f (updated codes)
          ]
        }
      ],
      "source": [
        "# ------------------------\n",
        "# ðŸ”¹ Phase IV-C: Retrain (Harden) Classifier\n",
        "# ------------------------\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# âš ï¸ device, classifier, mixed_loader already defined earlier\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Paths\n",
        "# ------------------------\n",
        "base_path = \".\"\n",
        "retrained_model_path = os.path.join(base_path, \"retrained_model\")\n",
        "os.makedirs(retrained_model_path, exist_ok=True)\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Loss & Optimizer (Lower LR for fine-tuning)\n",
        "# ------------------------\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(classifier.parameters(), lr=1e-4)\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Fine-tuning Loop\n",
        "# ------------------------\n",
        "def retrain_classifier(epochs=5):\n",
        "    classifier.train()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for images, labels in mixed_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = classifier(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "        acc = 100.0 * correct / total\n",
        "        print(\n",
        "            f\"Epoch [{epoch+1}/{epochs}] | \"\n",
        "            f\"Loss: {running_loss:.4f} | \"\n",
        "            f\"Accuracy: {acc:.2f}%\"\n",
        "        )\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Start Retraining\n",
        "# ------------------------\n",
        "retrain_classifier(epochs=5)\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Save Hardened Model\n",
        "# ------------------------\n",
        "save_file = os.path.join(retrained_model_path, \"classifier_hardened.pth\")\n",
        "torch.save(classifier.state_dict(), save_file)\n",
        "\n",
        "print(f\"âœ… Classifier Hardened & Saved at: {os.path.abspath(save_file)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49196c90",
      "metadata": {
        "id": "49196c90"
      },
      "source": [
        "Phase V: Evaluate and Visualize (Accuracy and GRAD-CAM)\n",
        "In this phase, you will:\n",
        "âœ” Compare accuracy before and after retraining\n",
        "âœ” Generate Grad-CAM heatmaps for visual explanation\n",
        "\n",
        "a) Test Accuracy (Before and After Training)"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 11,
      "id": "242ba342",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "242ba342",
        "outputId": "b9b74de3-253b-47cf-9b19-dd29f60ba97f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Accuracy Before Retraining: 80.37%\n",
            "âœ… Accuracy After Retraining:  83.23%\n",
            "ðŸ“„ Results saved to /content/results/accuracy_before_after.txt\n"
=======
      "execution_count": null,
      "id": "242ba342",
      "metadata": {
        "id": "242ba342",
        "outputId": "1c04d929-9165-42ca-f53e-286cb4f39ae7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Accuracy Before Retraining: 74.25%\n",
            "âœ… Accuracy After Retraining:  76.04%\n",
            "âœ… Results saved to .\\results\\accuracy_before_after.txt\n"
>>>>>>> 301c94f (updated codes)
          ]
        }
      ],
      "source": [
        "# ------------------------\n",
        "# ðŸ”¹ Phase V-A: Evaluate Accuracy (Before vs After Hardening)\n",
        "# ------------------------\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# âš ï¸ device and RobustCNN already defined earlier\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Paths\n",
        "# ------------------------\n",
        "base_path = \".\"\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Test Dataset\n",
        "# ------------------------\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5),\n",
        "                         (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "test_data = datasets.CIFAR10(\n",
        "    root=os.path.join(base_path, \"data\"),\n",
        "    train=False,\n",
        "    download=False,\n",
        "    transform=test_transform\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_data,\n",
        "    batch_size=64,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Accuracy Function\n",
        "# ------------------------\n",
        "def test_accuracy(model):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in test_loader:\n",
        "            imgs = imgs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(imgs)\n",
        "            preds = outputs.argmax(dim=1)\n",
        "\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    return 100.0 * correct / total\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Load Base Classifier\n",
        "# ------------------------\n",
        "base_model = RobustCNN().to(device)\n",
        "base_model.load_state_dict(\n",
        "    torch.load(os.path.join(base_path, \"models\", \"classifier.pth\"),\n",
        "               map_location=device)\n",
        ")\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Load Hardened Classifier\n",
        "# ------------------------\n",
        "hardened_model = RobustCNN().to(device)\n",
        "hardened_model.load_state_dict(\n",
        "    torch.load(os.path.join(base_path, \"retrained_model\", \"classifier_hardened.pth\"),\n",
        "               map_location=device)\n",
        ")\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Evaluate\n",
        "# ------------------------\n",
        "acc_before = test_accuracy(base_model)\n",
        "acc_after = test_accuracy(hardened_model)\n",
        "\n",
        "print(f\"âœ… Accuracy Before Retraining: {acc_before:.2f}%\")\n",
        "print(f\"âœ… Accuracy After Retraining:  {acc_after:.2f}%\")\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Save Results\n",
        "# ------------------------\n",
        "results_folder = os.path.join(base_path, \"results\")\n",
        "os.makedirs(results_folder, exist_ok=True)\n",
        "\n",
        "results_file = os.path.join(results_folder, \"accuracy_before_after.txt\")\n",
        "\n",
        "with open(results_file, \"w\") as f:\n",
        "    f.write(f\"Accuracy Before Retraining: {acc_before:.2f}%\\n\")\n",
        "    f.write(f\"Accuracy After Retraining:  {acc_after:.2f}%\\n\")\n",
        "\n",
        "print(f\"ðŸ“„ Results saved to {os.path.abspath(results_file)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b16470fc",
      "metadata": {
        "id": "b16470fc"
      },
      "source": [
        "b) GRAD-CAM Visualization (Why my Model Predict like this ?)"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 12,
      "id": "e1a23f54",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1a23f54",
        "outputId": "fb70330e-540d-4f02-b373-eb9020706f38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Grad-CAM saved at: /content/results/gradcam_outputs/gradcam_sample.png\n"
=======
      "execution_count": null,
      "id": "e1a23f54",
      "metadata": {
        "id": "e1a23f54",
        "outputId": "aa149244-f7d8-470f-c2b5-5650f31a3277"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Grad-CAM Saved at: .\\results\\gradcam_outputs\\gradcam_sample.png\n"
>>>>>>> 301c94f (updated codes)
          ]
        }
      ],
      "source": [
        "# ------------------------\n",
        "# ðŸ”¹ Phase V-B: Grad-CAM Visualization (Correct for RobustCNN)\n",
        "# ------------------------\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# âš ï¸ device, hardened_model, test_data already defined earlier\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Grad-CAM Class (Safe Hooks)\n",
        "# ------------------------\n",
        "class GradCAM:\n",
        "    def __init__(self, model, target_layer):\n",
        "        self.model = model\n",
        "        self.target_layer = target_layer\n",
        "        self.activations = None\n",
        "        self.gradients = None\n",
        "\n",
        "        # Forward hook\n",
        "        self.target_layer.register_forward_hook(self._forward_hook)\n",
        "        # Backward hook (new, safe API)\n",
        "        self.target_layer.register_full_backward_hook(self._backward_hook)\n",
        "\n",
        "    def _forward_hook(self, module, input, output):\n",
        "        self.activations = output.detach()\n",
        "\n",
        "    def _backward_hook(self, module, grad_input, grad_output):\n",
        "        self.gradients = grad_output[0].detach()\n",
        "\n",
        "    def generate(self, image, class_idx=None):\n",
        "        self.model.eval()\n",
        "        image = image.to(device)\n",
        "\n",
        "        # Forward\n",
        "        output = self.model(image)\n",
        "\n",
        "        if class_idx is None:\n",
        "            class_idx = output.argmax(dim=1).item()\n",
        "\n",
        "        # Backward\n",
        "        self.model.zero_grad()\n",
        "        output[0, class_idx].backward()\n",
        "\n",
        "        # ------------------------\n",
        "        # ðŸ”¹ Grad-CAM Computation\n",
        "        # ------------------------\n",
        "        weights = self.gradients.mean(dim=(2, 3), keepdim=True)\n",
        "        cam = (weights * self.activations).sum(dim=1, keepdim=True)\n",
        "        cam = F.relu(cam)\n",
        "\n",
        "        # Normalize\n",
        "        cam -= cam.min()\n",
        "        cam /= (cam.max() + 1e-8)\n",
        "\n",
        "        return cam.squeeze().cpu().numpy()\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Select Target Layer (Last Conv Layer)\n",
        "# ------------------------\n",
        "# RobustCNN.features:\n",
        "# [Conv, BN, ReLU, Conv, BN, ReLU, MaxPool,\n",
        "#  Conv, BN, ReLU, Conv, BN, ReLU, MaxPool]\n",
        "\n",
        "target_layer = hardened_model.features[10]  # Last Conv2d layer\n",
        "gradcam = GradCAM(hardened_model, target_layer)\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Select Test Image\n",
        "# ------------------------\n",
        "img, label = test_data[0]\n",
        "input_tensor = img.unsqueeze(0).to(device)\n",
        "\n",
        "cam = gradcam.generate(input_tensor)\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Create Heatmap\n",
        "# ------------------------\n",
        "cam_resized = cv2.resize(cam, (32, 32))\n",
        "heatmap = cv2.applyColorMap(np.uint8(255 * cam_resized), cv2.COLORMAP_JET)\n",
        "\n",
        "# Denormalize image for visualization\n",
        "img_np = img.permute(1, 2, 0).cpu().numpy()\n",
        "img_np = (img_np * 0.5 + 0.5)  # back to [0,1]\n",
        "img_np = np.uint8(255 * img_np)\n",
        "\n",
        "overlay = cv2.addWeighted(img_np, 0.5, heatmap, 0.5, 0)\n",
        "\n",
        "# ------------------------\n",
        "# ðŸ”¹ Save Output\n",
        "# ------------------------\n",
        "save_dir = os.path.join(base_path, \"results\", \"gradcam_outputs\")\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "save_path = os.path.join(save_dir, \"gradcam_sample.png\")\n",
        "cv2.imwrite(save_path, overlay)\n",
        "\n",
        "print(\"âœ… Grad-CAM saved at:\", os.path.abspath(save_path))\n"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 12,
=======
      "execution_count": null,
>>>>>>> 301c94f (updated codes)
      "id": "5b27bb83",
      "metadata": {
        "id": "5b27bb83"
      },
      "outputs": [],
      "source": []
<<<<<<< HEAD
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
=======
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "colab": {
      "provenance": []
    }
>>>>>>> 301c94f (updated codes)
  },
  "nbformat": 4,
  "nbformat_minor": 5
}